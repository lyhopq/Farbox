Title: k-近邻算法
Date: 2013-08-01 19:00
Tags: Machine Learning, 分类器

[TOC]

* * *

## 工作原理

    存在一个训练样本集，样本集中每个数据都存在标签（即分类）。
    输入的测试数据（没有标签）的每个特征与样本集中的每个特征进行比较，
    然后算法提取样本集中特征最相似数据（最邻近）的分类标签。
	通常，我们只选择数据集样本集中前k个最相似的数据。
	最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。


## k-近邻算法的一般流程

对未知类别的数据集中的每个点（**一个向量**)一次执行一下操作：

	1.   计算已知类别数据集中的点与当前点之间的距离;
	2.   按照距离递增次序排序;
	3.   选取与当前点距离最小的k个点;
	4.   确定k个点所在类别的出现概率;
	5.   返回前k个点出现概率最高的类别作为当前点的预测分类。

### 使用Matplotlib创建散点图

```Python
ax.scatter(datingDatMat[:, 1], datingDataMat[:, 2], 
		   15.0*array(datingLabels), 15.0*array(datingLabels))
```

### 归一化数据

当某些特征值远大于其它特征值时，会严重影响计算结果。在处理这种情况时，通常使用的方法是将数据归一化，如将取值范围处理为0到1或者-1到1之间。

	newValue = (oldVaule - min) / (max - min)


## 小结

优点： 
 
 1. 分类数据的最简单最有效的方法
 2. 精度高、对异常值不敏感、无数据输入假定

缺点：

 1. 计算复杂的高、空间复杂的高
 2. 无法给出任何数据的基础结构信息，因此无法知晓平均实例样本和典型实例样本具有什么特征

适用数据范围： 数值型和标称型 
