Title: 朴素贝叶斯
Date: 2013-08-06 18:30
Tags: Machine Learning, 分类器, 概率论

K-近邻和决策树分类器对数据实例有明确的分类答案，但是有时会产生错误的结果。而基于贝叶斯的分类器给出一个最优的类别猜测结果，同时给出这个猜测结果的概率估计值。

## 基于贝叶斯决策理论的分类方法

* 优点：在数据较少的情况下任然有效，可以处理多类别问题。
* 缺点：对于输入数据的准备方式较为敏感。
* 适用数据类型：标称型数据。

## 贝叶斯定理

贝叶斯定理描述两个事件的条件概率之间的关系。

$$P(H|E) = P(H)\frac{P(E|H)}{P(E)}$$

贝叶斯定理通常用于解释某一特定现象的证据$E$如何影响假设$H$的概率。

其中，$P(H)$称为*先验概率*，$P(H|E)$称为*后验概率*。$P(E|H)$是证据的*似然值*，$P(E)$是*归一化常量*。

## 训练算法：从词向量计算概率

词向量$w$定义为文档中每个单词在**单词列表**中的位置向量（出现为1,不出现为0）。那么，根据贝叶斯理论，该文档属于分类$i$的条件概率为：

$$p(c_i|w) = \frac{p(w|c_i)p(c_i)}{p(w)}$S

如果将$w$展开为一个个独立特征，那么：

<p align="center">$p(w|c_i) = p(w_0,w_1,w_2,...,w_N|c_i)$</p>

假设所有的词都独立（条件独立性假设），那么，$P(w|c_i)$简化为：

<p align="center">$p(w_0|c_i)p(w_1|c_i)...p(w_N|c_i)$</p>

这就是朴素贝叶斯的**朴素**所在。

### 算法修正

1. 计算$p(w_0|c_i)p(w_1|c_i)...p(w_N|c_i)$时，如果其中一个概率值为0,那么最后乘积值也为0。为了降低这种影响，可以将所有词的出现数初始化为1.
2. 计算$p(w_0|c_i)p(w_1|c_i)...p(w_N|c_i)$时，由于大部分因子都比较小，所以会出现下益或得不到正确答案。解决方法是对乘积取自然对数：
	$$\ln(a*b) = ln(a) + ln(b)$$






